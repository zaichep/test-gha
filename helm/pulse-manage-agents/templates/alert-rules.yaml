{{- if .Values.alertRules.enabled -}}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  namespace: {{ .Release.Namespace }}
  name: {{ include "pulse-manage-agents.fullname" . }}-rules
  labels:
    {{- include "pulse-manage-agents.labels" . | nindent 4 }}
    genesysengage/monitoring: prometheus
spec:
  groups:
    - name: Pulse Agent Management Alerts
      rules:
        - alert: pulse_am_service_down
          expr: (sum by (service) (up{service=~".*pulse-manage-agents.*"}) or on() vector(0)) == 0
          for: 300s
          labels:
            action: email
            severity: Critical
            {{- include "pulse-manage-agents.alertLabels" . | nindent 12 }}
          annotations:
            summary: "All Agent Management servers report they are not UP."
            information: "Number of Agent Management servers that are UP: {{`{{ $value }}`}} for Service: {{`{{ $labels.service }}`}}"

        - alert: pulse_am_high_5xx_responses
          expr: ((sum(
            rate(pulse_manage_agents_responses_total{code="5xx"}[1h]))
            by (service) /
            sum(rate(pulse_manage_agents_requests_total[1h])) by (service)))
            > 0.3
          for: 100s
          labels:
            action: email
            severity: Critical
            {{- include "pulse-manage-agents.alertLabels" . | nindent 12 }}
          annotations:
            summary: "More than 30% of responses during the last 1 hour have 5xx http status (this includes health check)."
            information: "Percent of responses with 5xx http status: {{`{{ $value }}`}}% for Service: {{`{{ $labels.pod }}`}}"

        - alert: pulse_am_crashing_container_detected
          expr: (time() - container_last_seen{container="pulse-manage-agents"}) > 60
          for: 5m
          labels:
            action: email
            severity: Warning
            {{- include "pulse-manage-agents.alertLabels" . | nindent 12 }}
          annotations:
            summary: "Agent Management container has not responded for more than 60 seconds."
            information: "Seconds since container was last responsive: {{`{{ $value }}`}} for Agent Management container {{`{{ $labels.container }}`}} of Service: {{`{{ $labels.pod }}`}}"

        - alert: pulse_am_container_high_cpu_usage
          # The container name= is defined by the HOST_NAME environment variable in the task definition in Agent Management's CloudFormation stack.
          expr: sum by (pod, container) (rate(container_cpu_usage_seconds_total{container="pulse-manage-agents"}[5m])) * 100 > 80
          for: 5m
          labels:
            action: email
            severity: Critical
            {{- include "pulse-manage-agents.alertLabels" . | nindent 12 }}
          annotations:
            summary: "Detected high CPU usage by Agent Management container."
            information: "Detected high CPU usage: {{`{{ $value }}`}} by Agent Management container {{`{{ $labels.container }}`}} of Service: {{`{{ $labels.pod }}`}}"

        - alert: pulse_am_container_high_memory_usage
          expr:  ceil(sum(container_memory_working_set_bytes{pod=~".*pulse-manage-agents.*"}) by (pod, container) / sum(kube_pod_container_resource_limits_memory_bytes{pod=~".*pulse-manage-agents.*"}) by ( pod, container) * 100) > 60
          for: 5m
          labels:
            action: email
            severity: Critical
            {{- include "pulse-manage-agents.alertLabels" . | nindent 12 }}
          annotations:
            summary: "Detected high memory usage by Agent Management container."
            information: "Detected high memory usage: {{`{{ $value }}`}} % by Agent Management container {{`{{ $labels.container }}`}} of Service: {{`{{ $labels.pod }}`}}"

{{- end -}}
